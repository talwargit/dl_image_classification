{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8309392",
   "metadata": {},
   "source": [
    "## Project 7- Image Segmentation and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ff200",
   "metadata": {},
   "source": [
    "Healthcare organizations often deal with a significant volume of handwritten medical documents, including forms, prescriptions, and patient records. Manual digitization and analysis of these documents are time-consuming, error-prone, and resource-intensive, leading to inefficiencies and potential errors in patient care. To address these challenges, there is a need for an automated system that can accurately digitize and classify handwritten characters on medical documents, enabling efficient data entry and analysis.\n",
    "      \n",
    "Develop a deep learning-based solution capable of accurately classifying handwritten characters on medical documents using the MNIST dataset as a benchmark. The system should automatically process handwritten images, classify them into their respective digit categories (0 through 9), and output the digitized text for further analysis. The primary objective is to improve the efficiency, accuracy, and reliability of digitization processes in healthcare, ultimately enhancing patient care and administrative workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c1222",
   "metadata": {},
   "source": [
    "**Dataset Download details**\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "**Loading (downloaded if needed) the MNIST dataset** \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd905dc0",
   "metadata": {},
   "source": [
    "***Data Dictionary***\n",
    "\n",
    "The mnist_train.csv file contains the 60,000 training examples and labels. The mnist_test.csv contains 10,000 test examples and labels. Each row consists of 785 values: the first value is the label (a number from 0 to 9) and the remaining 784 values are the pixel values (a number from 0 to 255)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f6799d",
   "metadata": {},
   "source": [
    "**Initial Guidelines:**\n",
    "\n",
    "1.Ensure to follow to Use Id’s provided by UNext for naming file as conventions.\n",
    "2.Create GitHub account and submit the GitHub link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8b2fd",
   "metadata": {},
   "source": [
    "### Software Engineering aspect:  \n",
    "\n",
    "Utilize software engineering aspects while building Machine learning model using modular programming principles to organize your code into reusable functions or classes to enhance readability, maintainability, and collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2900ef8",
   "metadata": {},
   "source": [
    "### General Instructions\n",
    "\n",
    "- The cells in the Jupyter notebook can be executed any number of times for testing the solution\n",
    "- Refrain from modifying the boilerplate code as it may lead to unexpected behavior\n",
    "- The solution is to be written between the comments `# code starts here` and `# code ends here`\n",
    "- On completing all the questions, the assessment is to be submitted on moodle for evaluation\n",
    "- Before submitting the assessment, there should be `no error` while executing the notebook. If there are any error causing code, please comment it.\n",
    "- The kernel of the Jupyter notebook is to be set as `Python 3 (ipykernel)` if not set already\n",
    "- Include imports as necessary\n",
    "- For each of the task, `Note` section will provide you hints to solve the problem.\n",
    "- Do not use `PRINT` statement inside the `Except` Block. Please use `return` statement only within the except block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee23936",
   "metadata": {},
   "source": [
    "### Task 1: Load the dataset and perform preliminary EDA (Exploratory Data Analysis) with key observations and insights-      (weightage - 10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372fe55",
   "metadata": {},
   "source": [
    "#### T1.1Load the MNIST dataset using try and except blocks. State the dimensions of Train and Test dataset  (weightage – 1 mark)           (AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3910c48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 14:30:42.385745: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-18 14:30:43.421268: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-18 14:30:43.425229: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-18 14:30:45.574174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d258a",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Design a method named `load_mnist_data` to load the MNIST dataset using TensorFlow's `tf.keras.datasets.mnist.load_data() method`.\n",
    "* Load the MNIST data using `tf.keras.datasets.mnist.load_data()` and unpack the returned tuples. \n",
    "* Return X train,y train, X test and y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4560f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    try:\n",
    "        # Load MNIST data\n",
    "        (X_train,y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data() \n",
    "        return X_train,y_train, X_test, y_test\n",
    "    except Exception as e:\n",
    "        return \"An error occurred while loading MNIST data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0fc05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train, X_test, y_test= load_mnist_data()\n",
    "\n",
    "if X_train is not None:\n",
    "    print(\"MNIST data loaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to load MNIST data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0e52c5-6328-41e0-b0d3-2d2aeec13d3d",
   "metadata": {},
   "source": [
    "##### Dimension of the Train and Test Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db9877b",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Design a method named `check_dimensions` to check the dimensions (number of dimensions) of multiple numpy arrays.\n",
    "* Use the `*arrays` syntax to accept a variable number of arrays as input.\n",
    "* Use the `ndim` attribute to get its number of dimensions (array.ndim) and append it to the `dimensions` list.\n",
    "* Return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecf65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dimensions(*arrays):\n",
    "    dimensions = []\n",
    "    # Code starts here\n",
    "    for array in arrays:\n",
    "        dimensions.append(array.ndim)\n",
    "    # Code ends here\n",
    "    return dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9208354-0209-490b-a1b7-1ddd63c6115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 1, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_dimensions(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a336b6-cda1-41b5-9604-2966cca0bac5",
   "metadata": {},
   "source": [
    "#### Task 1.2: Shape of the Train and Test Dataset  (weightage – 1 mark)           (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706775e",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Design a method named `get_shapes` to retrieve the shapes (dimensions) of multiple numpy arrays.\n",
    "* Use the `arrays` syntax to accept a variable number of arrays as input.\n",
    "* Use the `shape` attribute to get its shape (array.shape) and append it to the shapes list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e5f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapes(*arrays):\n",
    "    shapes = []\n",
    "    # Code starts here\n",
    "    for array in arrays:\n",
    "        shapes.append(array.shape)\n",
    "    # Code ends here\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e20661-44d5-4571-805e-94197080d129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(60000, 28, 28), (60000,), (10000, 28, 28), (10000,)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_shapes(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff1b72-4a0e-4a1b-b396-124e2e4e4fab",
   "metadata": {},
   "source": [
    "#### T1.3: Visualize the image of 100, 101,201 & 600 image on the train dataset  (weightage – 1 mark)           (ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168add7",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Design a method named `visualize` to display a set of images from an array using matplotlib.\n",
    "* Use `plt.subplot()` to create subplots for each image and plot them accordingly.\n",
    "* Set the colormap to grayscale using `cmap='gray'` in `plt.imshow()` for grayscale visualization.\n",
    "* Adjust the subplot layout to ensure the images are displayed properly without overlapping. You can use plt.subplots() to create a figure with multiple subplots and control their arrangement.\n",
    "* Call `plt.show()` to display the plotted images after setting up the subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46bc071e-e130-4461-ad89-207539f20765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize():\n",
    "    import matplotlib.pyplot as plt\n",
    "# plot 4 images as gray scale\n",
    "    positions = [100,101,201,600]\n",
    "    images = [X_train[pos] for pos in positions]\n",
    "    labels = [y_train[pos] for pos in positions]\n",
    "    print(labels)\n",
    "    plt.figure(figsize=(8,2))\n",
    "    for i in range(len(positions)):\n",
    "        plt.subplot(1,len(positions), i+1)\n",
    "        plt.imshow(images[i], cmap=\"gray\")\n",
    "        plt.title(f\"Label {labels[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "# show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6edb92cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 1, 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa9938-64fc-4f48-9eaa-891dc4619a53",
   "metadata": {},
   "source": [
    "#### T1.4 : Represent the dataset X in a data frame after flattening the it ,and find out the first 5 values  (weightage - 1 mark) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7c48e",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Design a method named `preprocess_X_data` to reshape the input data (X_train and X_test) for further processing.\n",
    "* Use reshape to have 60000 rows and 28 * 28 columns.\n",
    "* Use reshape to have 10000 rows and 28 * 28 columns.\n",
    "* Return reshaped X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69f8469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_X_data(X_train, X_test):\n",
    "    # Reshape X_train and X_test\n",
    "    X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "    \n",
    "    # return reshaped X_train,X_test\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ace3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test=preprocess_X_data(X_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74857880",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Design a method named `convert_df` to convert NumPy arrays (X_train and X_test) to pandas DataFrames.\n",
    "* Use `pd.DataFrame()` to convert X_train and X_test to pandas DataFrames.\n",
    "* Assign the converted DataFrames to new variables\n",
    "* Return the converted X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cb38543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "def convert_df(X_train,X_test):\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    # return the converted X_train and X_test\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51283293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   778  779  780  781  782  783  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0  \n",
      "4    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 784 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   778  779  780  781  782  783  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0  \n",
      "4    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data using the function\n",
    "preprocessed_X_train, preprocessed_X_test = convert_df(X_train, X_test)\n",
    "print(preprocessed_X_train.head())\n",
    "print(preprocessed_X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c10e3-f8d9-493d-8998-da1ae85daed3",
   "metadata": {},
   "source": [
    "#### T1.5: Find out the summary statistics of X_train and X_test data set : (weightage - 1 mark) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d428e",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Design a method named `describe_data` to describe the statistical properties of the input data (X_train and X_test).\n",
    "* Use the reshape method to 2D arrays with a single dimension inferred automatically.\n",
    "* Reshape `X_train` and `X_test` to maintain the number of rows and infer the number of columns based on the data.\n",
    "* Convert the reshaped arrays to pandas DataFrames using `pd.DataFrame()`.\n",
    "* Use the `describe` method on the DataFrames to compute descriptive statistics (mean, std, min, max, quartiles) for each column.\n",
    "* Transpose the resulting descriptive statistics DataFrame using `transpose()` to have the statistics as rows and features as columns.\n",
    "* Return Train Description and Test Description in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e3b1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_data(X_train, X_test):\n",
    "    # Reshape to 2D arrays\n",
    "    X_train = X_train.reshape(X_train.shape[0],28,28)\n",
    "    X_test = X_test.reshape(X_test.shape[0],28,28)\n",
    "    # Convert to DataFrame and describe\n",
    "    X_train = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
    "    X_test = pd.DataFrame(X_test.reshape(X_test.shape[0],-1))\n",
    "    train_description = X_train.describe().transpose()\n",
    "    test_description = X_test.describe().transpose()\n",
    "    # Return Train Description and Test Description\n",
    "    return train_description, test_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec1ae864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count   mean     std  min  25%  50%  75%   max\n",
      "0    60000.0  0.000  0.0000  0.0  0.0  0.0  0.0   0.0\n",
      "1    60000.0  0.000  0.0000  0.0  0.0  0.0  0.0   0.0\n",
      "2    60000.0  0.000  0.0000  0.0  0.0  0.0  0.0   0.0\n",
      "3    60000.0  0.000  0.0000  0.0  0.0  0.0  0.0   0.0\n",
      "4    60000.0  0.000  0.0000  0.0  0.0  0.0  0.0   0.0\n",
      "..       ...    ...     ...  ...  ...  ...  ...   ...\n",
      "779  60000.0  0.002  0.3466  0.0  0.0  0.0  0.0  62.0\n",
      "780  60000.0  0.000  0.0000  0.0  0.0  0.0  0.0   0.0\n",
      "781  60000.0  0.000  0.0000  0.0  0.0  0.0  0.0   0.0\n",
      "782  60000.0  0.000  0.0000  0.0  0.0  0.0  0.0   0.0\n",
      "783  60000.0  0.000  0.0000  0.0  0.0  0.0  0.0   0.0\n",
      "\n",
      "[784 rows x 8 columns]\n",
      "       count  mean  std  min  25%  50%  75%  max\n",
      "0    10000.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "1    10000.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2    10000.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3    10000.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4    10000.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "..       ...   ...  ...  ...  ...  ...  ...  ...\n",
      "779  10000.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "780  10000.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "781  10000.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "782  10000.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "783  10000.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[784 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Describe data using the function\n",
    "train_description, test_description = describe_data(X_train, X_test)\n",
    "print(train_description)\n",
    "print(test_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c12b9-3336-441e-a828-c5f41966c0d8",
   "metadata": {},
   "source": [
    "#### T1.6 : State the mean & Standard deviation of the image in test dataset present on index 35 (weightage - 1 mark) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74571ea8",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Design a method named `calculate_mean_and_std_of_image` to compute the mean and standard deviation of an image.\n",
    "* Use NumPy's `np.mean()` function to calculate the mean value of the image pixels: mean_value = np.mean(image).\n",
    "* Similarly, use NumPy's `np.std()` function to calculate the standard deviation of the image pixels: `std_value = np.std(image)`.\n",
    "* Return Mean Value and the Standard value in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d398056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_std_of_image(test_data, index):\n",
    "    # Get the image at the specified index\n",
    "    image = test_data[index]\n",
    "    # Calculate mean and standard deviation\n",
    "    mean_value = np.mean(image)\n",
    "    std_value = np.std(image)\n",
    "    return mean_value, std_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "025f0648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.31887755102041\n",
      "80.99301022225657\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean and standard deviation using the function\n",
    "mean_value, std_value = calculate_mean_and_std_of_image(X_test, 35)\n",
    "\n",
    "print(mean_value)\n",
    "print(std_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a66999e-07ec-4bc4-abd9-d0d535071a95",
   "metadata": {},
   "source": [
    "#### T1.7: Plot the class frequency of y_train. Is there a class imbalance ? (weightage - 1 mark) (ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637b9db",
   "metadata": {},
   "source": [
    "#### Note\n",
    "* Visualize the distribution of classes in the training dataset y_train using a bar plot. \n",
    "* Calculate the frequency of each unique value in the Series y_train using `value_counts` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64cb4c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot\n",
    "train_labels = pd.Series(y_train)\n",
    "counts = train_labels.value_counts().sort_index()\n",
    "plt.figure(figsize=(10,6))\n",
    "counts.plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.xlabel(\"digits\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8bed46",
   "metadata": {},
   "source": [
    "#### T1.8: Normalize and scale the data (X_train, X_test) . Why is this step needed ? State the Normalized and Scaled Matrices  (weightage - 2 mark)(ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052219bd",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Design a method named `normalize_and_scale` to preprocess image data by normalizing and scaling pixel values.\n",
    "* Use the `reshape` method to flatten images in `X_train` and `X_test` to 2D arrays with one dimension for each pixel.\n",
    "* Scale pixel values in flattened arrays to range [0, 1] by dividing by 255.\n",
    "* Normalize X_train and X_test by dividing by 255\n",
    "* Apply scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "822e5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "def normalize_and_scale(X_train, X_test):\n",
    "    # Flatten the images\n",
    "    X_train_flatten = X_train.reshape(X_train.shape[0],-1)\n",
    "    X_test_flatten = X_test.reshape(X_test.shape[0],-1)\n",
    "    # Normalize inputs from 0-255 to 0-1\n",
    "    X_train_normalized = X_train_flatten / 255.0\n",
    "    X_test_normalized = X_test_flatten / 255.0\n",
    "    # Scale the features\n",
    "    X_train_scaled = scale(X_train_normalized)\n",
    "    X_test_scaled = scale(X_test_normalized)\n",
    "\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "154f26ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize and scale the features using the function\n",
    "X_train_scaled, X_test_scaled = normalize_and_scale(X_train, X_test)\n",
    "\n",
    "print(X_train_scaled)\n",
    "\n",
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75bf40e-fe10-4855-9184-18754a9080dc",
   "metadata": {},
   "source": [
    "#### T1.9: Reduce the data as per below :      (weightage - 1 mark) (AE)\n",
    "* X_train[0:2000,1:]\n",
    "* y_train[0:2000]\n",
    "* X_test[2001:5000,1:]\n",
    "* y_test[2001:5000] \n",
    "* state the dimension of the X_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb3515",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "* Design a method named `reduce_data_size` to reduce the size of both training and test datasets based on provided sizes.\n",
    "* Use slicing to select a subset of train_size samples from the beginning of `X_train` and `y_train`.\n",
    "* Slice X_train and y_train to select rows and labels up to a specified train_size\n",
    "* Similarly, use slicing to select a subset of test_size samples from `X_test` and `y_test`.\n",
    "* Determine the dimensions of the reduced test data (X_test_reduced_dim) using the `shape` attribute.\n",
    "* Return the Reduced X Train, Reduced Y train,Reduced X test, Reduced y test and the dimensions of the reduced X_test in the same order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "982a6e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data_size(X_train, y_train, X_test, y_test, train_size=2000, test_size=5000):\n",
    "    # Reduce the size of the training data\n",
    "    X_train_reduced = X_train[0:2000, 1:]\n",
    "    y_train_reduced = y_train[0:2000]\n",
    "\n",
    "    # Reduce the size of the test data\n",
    "    X_test_reduced = X_test[2001:5000, 1:]\n",
    "    y_test_reduced = y_test[2001:5000]\n",
    "    X_test_reduced_dim = X_test_reduced.shape\n",
    "    # Return the Reduced X Train, Reduced Y train,Reduced X test, Reduced y test and the dimensions of the reduced X_test in the same order\n",
    "    return X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced, X_test_reduced_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c515326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999, 783)\n"
     ]
    }
   ],
   "source": [
    "# Reduce the size of the data using the function\n",
    "X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced,X_test_dim = reduce_data_size(X_train, y_train, X_test, y_test)\n",
    "print(X_test_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a07b8b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa873fd",
   "metadata": {},
   "source": [
    "### Task 2: Building Models and Optimizations \n",
    "Build deep learning model for Image classification.  (weightage - 65 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5e154",
   "metadata": {},
   "source": [
    "#### T2.1 Train the data with Support Vector Classifier on linear kernel and state the accuracy and Confusion Matrix . Write down your observations. (weightage - 4 marks)  (AE & ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f5482",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a function named `linear` that trains and evaluates a linear Support Vector Classifier (SVC) model.\n",
    "* Initialize a Support Vector Classifier (SVC) with a linear kernel `(kernel='linear')`\n",
    "* Fit the classifier using the training data `(X_train_reduced and Y_train_reduced)`\n",
    "* Predict labels for the test data `(X_test_reduced)`\n",
    "* Calculate the accuracy using the `score` funtion of the model\n",
    "* Calculate the confusion matrix using `metrics.confusion_matrix` with true labels. \n",
    "* Funtion `linear` MUST return both the accuracy score and the confusion matrix from your linear model in the same order.\n",
    "* Return Accuracy and Confusion matrix in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f268889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "def linear(X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced):\n",
    "    #SVC model\n",
    "    svc = SVC(kernel='linear')\n",
    "    #Fit the model\n",
    "    svc.fit(X_train_reduced,y_train_reduced)\n",
    "    #predict\n",
    "    y_pred = svc.predict(X_test_reduced)\n",
    "    #Calculate Accuracy\n",
    "    accuracy = svc.score(X_test_reduced,y_test_reduced)\n",
    "    #Calculate Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test_reduced,y_pred)\n",
    "    #return accuracy, confusion matrix\n",
    "    return accuracy,conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0077567",
   "metadata": {},
   "source": [
    "##### accuracy-2 marks (AE), confusion_matrix(ME)-2marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aebd5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy\n",
    "accuracy = linear(X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdab5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matirx\n",
    "confusion_matrix= linear(X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e75e2b",
   "metadata": {},
   "source": [
    "#### T2.2 Train the data with Support Vector Classifier on rbf kernel with default gamma, and state the accuracy and Confusion Matrix    (weightage - 4 marks)  (AE)\n",
    "\n",
    "Write down your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4898a4",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a function named `train_non_linear_svm` with four parameters: `X_train_reduced, y_train_reduced, X_test_reduced, and y_test_reduced`\n",
    "* Create a Support Vector Classifier (SVC) with a radial basis function (RBF) kernel `(kernel='rbf')`\n",
    "* Train the classifier using the training data\n",
    "* Predict labels for the test data\n",
    "* Calculate the confusion matrix using `metrics.confusion_matrix` \n",
    "* Calculate the accuracy score using `non_linear_model.score` on the test data.\n",
    "* Funtion `train_non_linear_svm` MUST return both the accuracy score and the confusion matrix from your model in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73adf5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "# model\n",
    "def train_non_linear_svm(X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced):\n",
    "    # Create non-linear SVM model with RBF kernel\n",
    "    svc_rbf = SVC(kernel='rbf')\n",
    "    \n",
    "    # Train the model\n",
    "    svc_rbf.fit(X_train_reduced,y_train_reduced)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = svc_rbf.predict(X_test_reduced)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = svc_rbf.score(X_test_reduced,y_test_reduced)\n",
    "    \n",
    "    # Calculate Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test_reduced,y_pred)\n",
    "    #retun accuracy and confusion matrix\n",
    "    return accuracy, conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94fde44",
   "metadata": {},
   "source": [
    "##### accuracy-2 marks (AE), confusion_matrix(ME)-2marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cf4d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy\n",
    "accuracy=train_non_linear_svm(X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "102a7b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print confusion_matrix\n",
    "confusion_matrix=train_non_linear_svm(X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fb5508",
   "metadata": {},
   "source": [
    "#### T2.3 : **Model versioning** -    (weightage - 2 marks) ME\n",
    "\n",
    "Save the initial version of a Support Vector Classifier on linear kernel codebase named 'linear_model’ and Support Vector Classifier on rbf kernel codebase named 'rbf_model' to a version control system GitHub using git commands for collaboration, tracking changes, and ensuring transparency in model development. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac85137",
   "metadata": {},
   "source": [
    "#### Refer to the Github document from Lumen to create the repository and steps to commit \n",
    "#### Add your Github repository link below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ace1fbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/talwargit/dl_image_classification'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://github.com/talwargit/dl_image_classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c5c65",
   "metadata": {},
   "source": [
    "#### T2.4 : Perform Hyper parameter tuning  and find the optimal values of C and gamma corresponding to RBF kernel    (weightage - 5 marks)  ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75503b39",
   "metadata": {},
   "source": [
    "Use 5 fold cross validation \n",
    "Represent the cv results in a data frame and state your observations  \n",
    "Grid Search: Hyperparameter Tuning\n",
    "Tune the model to find the optimal values of C and gamma corresponding to an RBF kernel. \n",
    "Use 5-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4983d0c1",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a function named `train_svm_with_grid_search` with two parameters: `X_train_reduced` and `y_train_reduced`\n",
    "* Create a KFold cross-validation object with `5 splits` using `KFold`\n",
    "* Define a range of hyperparameters for the Support Vector Machine (SVM) model. Hyperparameters include `gamma` and `C`\n",
    "* Create an SVM model with a radial basis function `RBF` kernel\n",
    "* Set up a GridSearchCV object (model_cv) with the SVM model, hyperparameter range, scoring method `('accuracy')`, `KFold`, and set verbose=0\n",
    "* Fit the GridSearchCV object to the training data\n",
    "* Return the cross-validation results, best score and best hyperparameters in the same order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2aa7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a KFold object with 5 splits \n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "def train_svm_with_grid_search(X_train_reduced, y_train_reduced):\n",
    "    \n",
    "    # Define KFold cross-validation\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    \n",
    "    # Define range of hyperparameters\n",
    "    params = {\n",
    "        'C':[0.1, 1, 10 ,100],\n",
    "        'gamma':[1, 0.1, 0.01, 0.001]\n",
    "    }\n",
    "    \n",
    "    # Define SVM model\n",
    "    svc_rbf = SVC(kernel='rbf')\n",
    "    # Set up GridSearchCV.Set verbose=0 to suppress output.\n",
    "    grid_search = GridSearchCV(estimator=svc_rbf, param_grid=params, cv=kfold, scoring='accuracy', n_jobs=1, verbose=0)\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train_reduced, y_train_reduced)\n",
    "    # Return cross-validation results, best score and best hyperparameters\n",
    "\n",
    "    cv_results = grid_search.cv_results_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_hyperparams = grid_search.best_params_\n",
    "    return cv_results, best_score, best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffd185ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to train SVM model with grid search\n",
    "cv_results, best_score, best_hyperparams = train_svm_with_grid_search(X_train_reduced, y_train_reduced)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(f\"cross-validation results: {cv_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e2621",
   "metadata": {},
   "source": [
    "#### T2.5 State the optimal accuracy score and hyperparameters. (weightage - 5 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80184ba",
   "metadata": {},
   "source": [
    "- best_score (AE) weightage(3 marks)\n",
    "- hyperparameters (ME) weightage (2marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bef1801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.11099999999999999\n",
      "Best Hyperparameters: {'C': 0.1, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Call the function to train SVM model with grid search\n",
    "cv_results, best_score, best_hyperparams = train_svm_with_grid_search(X_train_reduced, y_train_reduced)\n",
    "\n",
    "# Display the best score best hyperparameters\n",
    "print(f\"Best Score: {best_score}\")\n",
    "print(f\"Best Hyperparameters: {best_hyperparams}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe21ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.1, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Display the best hyperparameters\n",
    "print(f\"Best Hyperparameters: {best_hyperparams}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c42f9b-1e15-4270-ba70-f63e2fda0c8d",
   "metadata": {},
   "source": [
    "#### T2.6 Build as base line model with Multilayered Perceptrons-1 layer  after one hot encoding the test data as per the architecture 784...> [784]--->10  (weightage - 5 marks) AE\n",
    "\n",
    "Train data should be normalized and scaled and state the accuracy with 10 epochs , with RELU and Softmax activation, State the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea88058-925c-485f-86f8-bce113250ef0",
   "metadata": {},
   "source": [
    "### BASE MODEL WITH 1 LAYER "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad016b7",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a function named `build_and_train_mlp_on_reduced_data` with five parameters: `X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced, epochs`\n",
    "* One-hot encode the labels using `to_categorical`\n",
    "* Define the MLP model using `Sequential`\n",
    "* Add a dense layer with 784 units and ReLU activation as the input layer and hidden layer.\n",
    "* Add a dense layer with 10 units and softmax activation as the output layer for multiclass classification.\n",
    "* Compile the model using `Adam optimizer` and `categorical crossentropy` loss function.\n",
    "* Train the model using `model.fit`, with training data, labels, number of epochs, batch size, validation split of 0.1, and set verbose =0.\n",
    "* Evaluate the model on test data using `model.evaluate`\n",
    "* Return the test accuracy and the keys of the history dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c3c4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def build_and_train_mlp_on_reduced_data(X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced, epochs=10, batch_size=32, verbose=0):\n",
    "    # Normalize and scale the training and test data\n",
    "\n",
    "    X_train = X_train_reduced.astype('float32') / 255.0\n",
    "    X_test = X_test_reduced.astype('float32') / 255.0\n",
    "    # One-hot encode the labels\n",
    "    y_train = to_categorical(y_train_reduced,10)\n",
    "    y_test = to_categorical(y_test_reduced,10)\n",
    "    # Define the MLP model (keep input_shape=(X_train_reduced.shape[1],))\n",
    "    model = Sequential()\n",
    "    # Input layer and hidden layer\n",
    "    model.add(Dense(784, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    # Output layer with softmax activation for multiclass classification\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # Compile the model (optimizer='adam')\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    # Train the model. Set verbose=0 to suppress output.\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "    # Evaluate the model on test data. Set verbose=0 to suppress output.\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    # Return the test accuracy and the keys of the history dictionary\n",
    "    return test_accuracy, history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51ee56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to build, train, and evaluate the MLP model on reduced size data\n",
    "test_accuracy, history_keys = build_and_train_mlp_on_reduced_data(X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6fecd",
   "metadata": {},
   "source": [
    "#### T2.7 state the history keys post incorporating the validation_split=0.33  (weightage - 2 marks) ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ed45d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8899633288383484,\n",
       " dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy']))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy, history_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80c9937",
   "metadata": {},
   "source": [
    "#### T2.8: Plot a graph to summarize the history for accuracy , validation_accuracy, loss , validation_loss (weightage - 5 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb8fae",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a function named `build_and_train_mlp_on_reduced_data` with five parameters: `X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced, epochs`\n",
    "* Normalize and scale the training and test data \n",
    "* One-hot encode the labels using `to_categorical`\n",
    "* Define the MLP model using `Sequential`\n",
    "* Add a dense layer with 784 units and ReLU activation, serving as both input and hidden layer. Follow it \n",
    "  with a dense layer featuring 10 units and softmax activation for multiclass classification.\n",
    "* Compile the model using `Adam optimizer` and `categorical crossentropy` loss function.\n",
    "* Train the model using `model.fit`, with training data, labels, number of epochs, batch size, validation   split of 0.1, and set verbose = 0.\n",
    "* Evaluate the model on test data using `model.evaluate`\n",
    "* Plot the training and validation accuracy and loss using `plt.plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3157a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_mlp_on_reduced_data_graph(X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced, epochs=10, batch_size=32, verbose=0):\n",
    "    # Normalize and scale the training and test data\n",
    " \n",
    "    \n",
    "    # One-hot encode the labels\n",
    "    \n",
    "    \n",
    "    # Define the MLP model\n",
    "\n",
    "    \n",
    "    # Compile the model\n",
    "   \n",
    "    # Train the model. Set verbose=0 to suppress output.\n",
    "    \n",
    "    # Evaluate the model on test data. Set verbose=0 to suppress output.\n",
    "    \n",
    "    # Plot history\n",
    "    \n",
    "\n",
    "    # Call the function to build, train, and evaluate the MLP model on reduced size data\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da22ce",
   "metadata": {},
   "source": [
    "#### T2.9 Generate a prediction matrix for X_test (weightage - 3 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10085da",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a function named `build_and_train_mlp_on_reduced_data_1` with five parameters: `X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced, epochs`\n",
    "* Normalize and scale the training and test data \n",
    "* One-hot encode the labels using `to_categorical`\n",
    "* Define the MLP model using `Sequential`\n",
    "* Begin with a dense layer featuring 784 units and ReLU activation, serving as both input and hidden layer. \n",
    "  Then, append a dense layer with 10 units and softmax activation, suitable for multiclass classification.\n",
    "* Compile the model using `Adam optimizer` and `categorical crossentropy` loss function.\n",
    "* Train the model using `model.fit`, with training data, labels, number of epochs, batch size, validation split of 0.1, and set verbose = 0.\n",
    "* Evaluate the model on test data using `model.evaluate`\n",
    "* Make predictions for the test data using `model.predict`\n",
    "* Retun test_accuracy, predictions om the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1655b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_mlp_on_reduced_data_1(X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced, epochs=10, batch_size=32, verbose=0):\n",
    "    # Normalize and scale the training and test data\n",
    "\n",
    "    \n",
    "    # One-hot encode the labels\n",
    "\n",
    "    \n",
    "    # Define the MLP model\n",
    "\n",
    "   \n",
    "    # Compile the model\n",
    "\n",
    "    \n",
    "    # Train the model. Set verbose=0 to suppress output.\n",
    "\n",
    "    \n",
    "    # Evaluate the model on test data. Set verbose=0 to suppress output.\n",
    "\n",
    "    \n",
    "    # Predictions for X_test.Set verbose=0 to suppress output.\n",
    "    \n",
    "\n",
    "    #retun test_accuracy, predictions    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "843758aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to build, train, and evaluate the MLP model on reduced size data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ddc0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0b7c4831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print prediction matrix for X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c04d05",
   "metadata": {},
   "source": [
    "#### T2.10: Build the model with 2 hidden layers with 120 neurons in the second layer with tanh activation and state the accuracy  (weightage - 7 marks) AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6bda27",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a function named `preprocess_data` with four parameters: `X_train, X_test, y_train, and y_test`\n",
    "  Inside the function:\n",
    "    * Scale the input features using `StandardScaler`\n",
    "    * One-hot encode the target labels using `LabelBinarizer`\n",
    "* Return the preprocessed data: Normalised X_train, Normalised X_test,one hot encoded y_train,one hot encoded y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b1d815cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    # Scale the input features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    # One-hot encode the target labels\n",
    "    lb = LabelBinarizer()\n",
    "    y_train_bin = lb.fit_transform(y_train)\n",
    "    y_test_bin = lb.fit_transform(y_test)\n",
    "    # Return the preprocessed data: Normalised X_train, Normalised X_test,one hot encoded y_train,one hot encoded y_test\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train_bin, y_test_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72c91f",
   "metadata": {},
   "source": [
    "* Define a function named `create_model` with two parameters: `input_dim and num_classes`.      \n",
    "  Inside the function:\n",
    "    * Create a Sequential model.\n",
    "    * Start with a Dense layer with ReLU activation, followed by another Dense layer with hyperbolic tangent activation, and conclude with a Dense layer using softmax activation.\n",
    "    * Compile the model using `categorical crossentropy loss` and `Adam optimizer`\n",
    "* Preprocess the data using the `preprocess_data` function.\n",
    "* Create the model using the `create_model function` with appropriate parameters.\n",
    "* Train the model using the `fit method`, with the preprocessed training data, one-hot encoded training labels, number of epochs, batch size, validation split of 0.1, and set verbose = 0.\n",
    "* retun model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9c9b44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=(input_dim,)))\n",
    "    model.add(Dense(50, activation='tanh'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    #Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "471bcbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming num_pixels and num_classes are defined appropriately\n",
    "num_pixels = 783\n",
    "num_classes = 10\n",
    "\n",
    "# Preprocess the data\n",
    "X_train, X_test, y_train, y_test = preprocess_data(X_train_reduced, X_test_reduced, y_train_reduced, y_test_reduced)\n",
    "\n",
    "# Create the model\n",
    "model = create_model(num_pixels, num_classes)\n",
    "\n",
    "# Train the model. Set verbose=0 to suppress output.\n",
    "history = model.fit(X_train, y_train, epochs=1, batch_size=32, validation_split=0.1, verbose=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "76af8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model. Set verbose=0 to suppress output.\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b912aa",
   "metadata": {},
   "source": [
    "#### T2.11 Model versioning - Save the above version of a model with 2 hidden layers codebase named 'new_model’ to a version control system GitHub using git commands for collaboration, tracking changes, and ensuring transparency in model development. And bring the model and do evaluation.  (weightage - 3 marks)  ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca9274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d1692b1",
   "metadata": {},
   "source": [
    "#### T2.12 Optimize the previous 2 layered model with Drop out regularization of 0.1 in each of the layers State the accuracy  (weightage - 10 marks) AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3047d",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a function named `baseline_model_with_dropout`\n",
    "    * Create a Sequential model.\n",
    "    * Sequentially add Dense layers with ReLU activation, Dropout regularization, another Dense layer with hyperbolic tangent activation, another Dropout layer, and finalize with a Dense layer using softmax activation\n",
    "    * Compile the model using `categorical crossentropy loss` and `Adam optimizer`\n",
    "    * Return the model\n",
    "    \n",
    "* Create the model using the `baseline_model_with_dropout function`\n",
    "* Train the model using the `fit method`, with the preprocessed training data, one-hot encoded training labels, number of epochs, batch size, validation split of 0.1, and set verbose = 0.\n",
    "* Evaluate the model using the evaluate method with the preprocessed test data and one-hot encoded test labels, and print the test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25fad44-0147-4e4d-878f-8105105e1e09",
   "metadata": {},
   "source": [
    "##### Applying Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a007f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train, X_test, y_test= load_mnist_data()\n",
    "X_train_reduced = X_train[0:2000]\n",
    "y_train_reduced = y_train[0:2000]\n",
    "\n",
    "# Reduce the size of the test data\n",
    "X_test_reduced = X_test[2001:5000]\n",
    "y_test_reduced = y_test[2001:5000]\n",
    "X_train = X_train_reduced.astype('float32') / 255.0\n",
    "X_test = X_test_reduced.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train_reduced,10)\n",
    "y_test = to_categorical(y_test_reduced,10)\n",
    "X_train = X_train.reshape(-1,784)\n",
    "X_test = X_test.reshape(-1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0f5db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "def baseline_model_with_dropout():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(50, activation='tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    # Return the model\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = baseline_model_with_dropout()\n",
    "\n",
    "# Train the model.Set verbose=0 to suppress output.\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Evaluate the model.Set verbose=0 to suppress output.\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360bd4e",
   "metadata": {},
   "source": [
    "#### T2.13 : Train the dataset using CONV2D AND DROP OUT 0.2.State the accuracy and write your observations.  (weightage - 10 marks) AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53012a4",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a function named `cnn_model_with_dropout`\n",
    "* Sequentially apply convolutional and pooling layers, flatten the output, add a fully connected layer with ReLU activation and dropout, and finalize with a softmax layer\n",
    "* Compile the model using `Adam optimizer` and `categorical crossentropy loss`\n",
    "* Create the CNN model with dropout using the `cnn_model_with_dropout function`\n",
    "* Train the model using the `fit method`, with the reshaped preprocessed training data, one-hot encoded training labels, number of epochs, batch size, validation split of 0.1, and set verbose = 0.\n",
    "* Evaluate the model using the evaluate method with the reshaped preprocessed test data and one-hot encoded test labels, and print the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "31b12b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train, X_test, y_test= load_mnist_data()\n",
    "X_train_reduced = X_train[0:2000]\n",
    "y_train_reduced = y_train[0:2000]\n",
    "\n",
    "# Reduce the size of the test data\n",
    "X_test_reduced = X_test[2001:5000]\n",
    "y_test_reduced = y_test[2001:5000]\n",
    "X_train = X_train_reduced.astype('float32') / 255.0\n",
    "X_test = X_test_reduced.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train_reduced,10)\n",
    "y_test = to_categorical(y_test_reduced,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9ecd6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def cnn_model_with_dropout():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    # return Model\n",
    "    return model\n",
    "\n",
    "# Create the CNN model with dropout\n",
    "model = cnn_model_with_dropout()\n",
    "\n",
    "# Train the model.Set verbose=0 to suppress output.\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "\n",
    "# Evaluate the model.Set verbose=0 to suppress output.\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67456b",
   "metadata": {},
   "source": [
    "### Task 3: Model Deployment: Deploy the trained model into a production environment,  allowing stakeholders to utilize it for real-time forecasting Develop an  intuitive user interface to facilitate easy interaction with the model.                                                                                             (weightage – 10 marks)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76db5f",
   "metadata": {},
   "source": [
    "#### T3.1 Using Lime/SHAP libraries, explain the prediction of your model and give inferences (weightage - 4 marks) ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8723ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "025571dd",
   "metadata": {},
   "source": [
    "#### T3.2 Implement the unit test case and deploy a model (saving the file as a .t5 model). Using the saved .t5 model file to create a webapp using flask/streamlit code  (weightage - 6 marks) ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b9521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe5819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cbb11a7",
   "metadata": {},
   "source": [
    "### Task 4: Summarize the findings of the analysis and draw conclusions with PPT / PDF.                                                                                   (weightage - 15 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6370f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2fd2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa17b018",
   "metadata": {},
   "source": [
    "**Final Submission guidelines:**  \n",
    "\n",
    "- Download the Jupyter notebook in the format of html.  \n",
    "- Upload it in the lumen (UNext LMS) \n",
    "- Take a screenshot of T3.2 (Deployment) and upload it in the lumen (UNext LMS) \n",
    "- Summarized PPT/ PDF prepared in Task 4 to be uploaded in the lumen (UNext LMS) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
